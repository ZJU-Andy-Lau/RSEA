{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from model_new import Encoder\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614625be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_large = {\n",
    "        'input_channels':3,\n",
    "        'patch_feature_channels':512,\n",
    "        'global_feature_channels':256,\n",
    "        'img_size':1024,\n",
    "        'window_size':16,\n",
    "        'embed_dim':192,\n",
    "        'depth':[2,2,18],\n",
    "        'num_heads':[6, 12, 24],\n",
    "        'drop_path_rate':.2,\n",
    "        'pretrain_window_size':[12, 12, 12],\n",
    "        'unfreeze_backbone_modules':['head','norm','layers.2.blocks.14','layers.2.blocks.15','layers.2.blocks.16','layers.2.blocks.17']\n",
    "    }\n",
    "\n",
    "encoder_path = ''\n",
    "encoder = Encoder(cfg_large)\n",
    "encoder = encoder.eval().cuda()\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                ])\n",
    "encoder.load_state_dict({k.replace(\"module.\",\"\"):v for k,v in torch.load(encoder_path).items()},strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae38a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = ''\n",
    "data_idx = 0\n",
    "\n",
    "def get_color(score,div):\n",
    "    if score < div:\n",
    "        return (255,0,0)\n",
    "    else:\n",
    "        return (0,255,0)\n",
    "\n",
    "with h5py.File(dataset_path,'r') as f:\n",
    "    keys = list(f.keys())\n",
    "    img_raw = f[keys[data_idx]]['image_1'][:][988:2012,988:2012]\n",
    "\n",
    "img = np.stack([img_raw] * 3,axis=-1)\n",
    "img = transform(img)[None]\n",
    "\n",
    "feat,conf = encoder(img)\n",
    "conf = conf.squeeze()\n",
    "\n",
    "img_output = img_raw\n",
    "for line in range(conf.shape[0]):\n",
    "    for samp in range(conf.shape[1]):\n",
    "        cv2.circle(img_output,((samp + .5) * 16.,(line + .5) * 16),1,get_color(conf[line,samp],.5),-1)\n",
    "\n",
    "Image.fromarray(img_output).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639a8787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1500 + 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
